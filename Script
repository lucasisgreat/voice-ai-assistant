#!/usr/bin/env python3
# llama_bot.py ‚Äî Chat + overlapped XTTS with auto reference splitting
# - LLM via llama.cpp (GPU offload if available)
# - XTTS worker in a subprocess (GPU optional)
# - Auto-splits long reference audio into 24 kHz mono segments
# - Streams tokens; flushes short phrases early for snappier speech
# - Audio playback fallback: paplay ‚Üí aplay ‚Üí ffplay
# - Keeps chat history in RAM during the session; wipes on exit (no disk logs)

import os
import sys
import re
import atexit
import signal
import tempfile
import subprocess
import threading
import queue
import time
import logging
from pathlib import Path
from typing import List, Tuple, Optional

# ================= User config =================
MODEL_PATH       = "/mnt/c/models/openhermes-2.5-mistral-7b.Q4_K_M.gguf"
MODEL_DIR        = "/mnt/c/models"  # Directory containing your models
REF_AUDIO_DIR    = "/mnt/c/Users/PC/Desktop/voice_samples/freeman_refs"
VOICE_BASE_DIR   = "/mnt/c/Users/PC/Desktop/voice_samples"  # Base directory for all voices
XTTS_MODEL_NAME  = "tts_models/multilingual/multi-dataset/xtts_v2"

DEFAULT_CHARACTER = (
    "You are warm and steady. Speak in short, natural sentences (6‚Äì12 words). "
    "Prefer everyday words. Add brief pauses around commas or conjunctions. "
    "Answer directly. Avoid lists unless asked."
)

# Phrase & audio knobs
TARGET_SR          = 24000
PEAK_DBFS          = -1.0
MIN_CHARS_TO_FLUSH = 35       # Moderate increase - still conversational
PHRASE_CHAR_MAX    = 140      # Keep original - short phrases
PUNCT              = ".?!"    # Only sentence endings
STRONG_PUNCT       = ".?!"    # Only break on sentence endings
MAX_TOKENS         = 140
TTS_LANGUAGE       = "en"
SPEECH_SPEED       = 1.15

# LLM perf knobs - BALANCED FOR SPEED
N_THREADS     = int(os.environ.get("N_THREADS", "8"))      # Back to 8
N_CTX         = int(os.environ.get("N_CTX",     "2048"))   # Larger context is actually faster
N_BATCH       = int(os.environ.get("N_BATCH",   "512"))    # Optimized batch size
N_GPU_LAYERS  = int(os.environ.get("N_GPU_LAYERS", "-1"))

# TTS Performance knobs
TTS_USE_DEEPSPEED = os.environ.get("TTS_USE_DEEPSPEED", "0") == "1"
TTS_NUM_THREADS = int(os.environ.get("TTS_NUM_THREADS", "4"))

# Reference splitting knobs (env overrides OK)
SEG_SEC       = int(os.environ.get("SEG_SEC", "6"))      # target segment length
MAX_REF_CLIPS = int(os.environ.get("MAX_REF_CLIPS", "17"))  # More refs = better quality

# Memory management
MAX_HISTORY_MESSAGES = int(os.environ.get("MAX_HISTORY_MESSAGES", "20"))  # Keep last N messages

# Behavior: keep chat memory while running; wipe on exit only
WIPE_HISTORY_ON_EXIT = True
VOICE_INPUT_ENABLED = False
VOICE_ENERGY_THRESHOLD = 300
VOICE_PAUSE_THRESHOLD = 0.8

# Worker ready timeout
TTS_WORKER_READY_TIMEOUT = 60  # seconds
# =======================================================

# Quieter logs
os.environ.setdefault("TRANSFORMERS_VERBOSITY", "error")
os.environ.setdefault("PYTHONWARNINGS", "ignore")
os.environ.setdefault("GGML_CUDA_FORCE_DMMV", "1")

IS_TTS_WORKER = ("--tts-worker" in sys.argv)

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ----------------- GPU helpers -----------------
def _gpu_list() -> List[Tuple[int, int]]:
    """Query available GPUs and their VRAM. Returns list of (index, vram_mb) tuples."""
    try:
        out = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=index,memory.total", "--format=csv,noheader,nounits"],
            text=True,
            stderr=subprocess.DEVNULL
        ).strip().splitlines()
        return [(int(l.split(",")[0]), int(l.split(",")[1])) for l in out]
    except (subprocess.CalledProcessError, FileNotFoundError, ValueError):
        return []

def _largest_vram_index() -> str:
    """Get GPU index with largest VRAM, or empty string if none available."""
    pairs = _gpu_list()
    if not pairs:
        return ""
    return str(sorted(pairs, key=lambda x: x[1], reverse=True)[0][0])

# ----------------- audio helpers -----------------
def ffmpeg_exists() -> bool:
    """Check if ffmpeg is available."""
    try:
        subprocess.run(
            ["ffmpeg", "-version"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            check=True,
            timeout=5
        )
        return True
    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
        return False

def play_wav_file(path: str) -> bool:
    """
    Play a WAV file using available audio player.
    Tries paplay, aplay, then ffplay in order.
    Returns True if playback succeeded.
    """
    if not os.path.isfile(path):
        logger.warning(f"Audio file not found: {path}")
        return False
    
    candidates = (
        ["paplay", path],
        ["aplay", path],
        ["ffplay", "-nodisp", "-autoexit", path],
    )
    for cmd in candidates:
        try:
            subprocess.run(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True,
                timeout=30
            )
            return True
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    return False

# ----------------- temp tracking & cleanup -----------------
_temp_dir: Optional[tempfile.TemporaryDirectory] = None

def _init_temp_dir() -> str:
    """Initialize and return path to temporary directory for this session."""
    global _temp_dir
    if _temp_dir is None:
        _temp_dir = tempfile.TemporaryDirectory(prefix="llama_bot_")
    return _temp_dir.name

def _cleanup_temps(*_):
    """Cleanup temporary directory on exit."""
    global _temp_dir
    if _temp_dir is not None:
        try:
            _temp_dir.cleanup()
        except Exception as e:
            logger.warning(f"Failed to cleanup temp dir: {e}")
        _temp_dir = None

atexit.register(_cleanup_temps)

def _get_temp_file(suffix: str = ".wav") -> str:
    """Get path to a new temporary file."""
    temp_dir = _init_temp_dir()
    fd, path = tempfile.mkstemp(suffix=suffix, dir=temp_dir)
    os.close(fd)  # Close fd, we just need the path
    return path

# ------------- reference splitting -------------
def _gather_segments(ref_dir: str) -> List[str]:
    """Gather all reference audio segments from ref_dir and chunks subdirectory."""
    segs: List[str] = []
    ref_path = Path(ref_dir)
    
    if not ref_path.exists():
        return segs
    
    # pre-created ref_XX.wav in root
    for f in sorted(ref_path.glob("ref_*.wav")):
        segs.append(str(f))
    
    # chunks tree
    chunks = ref_path / "chunks"
    if chunks.is_dir():
        for f in sorted(chunks.rglob("seg_*.wav")):
            segs.append(str(f))
    
    return sorted(segs)

def auto_split_refs(ref_dir: str, seg_sec: int = SEG_SEC, max_copy: int = MAX_REF_CLIPS) -> List[str]:
    """
    Split any mp3/wav/flac/m4a in ref_dir into short 24k mono PCM16 WAV clips under:
      ref_dir/chunks/<base>/seg_XXX.wav
    Return up to max_copy segment paths (sorted).
    
    Args:
        ref_dir: Directory containing reference audio files
        seg_sec: Target segment length in seconds
        max_copy: Maximum number of segments to return
        
    Returns:
        List of paths to audio segment files
    """
    ref_path = Path(ref_dir)
    ref_path.mkdir(parents=True, exist_ok=True)
    chunks_dir = ref_path / "chunks"
    chunks_dir.mkdir(exist_ok=True)
    
    suffixes = (".mp3", ".wav", ".flac", ".m4a", ".MP3", ".WAV", ".FLAC", ".M4A")
    sources = [f for f in ref_path.iterdir() if f.is_file() and f.suffix in suffixes]
    
    if not sources:
        segments = _gather_segments(ref_dir)
        return segments[:max_copy]
    
    surfaced: List[str] = []

    for src in sources:
        # Validate source path to prevent command injection
        src_str = str(src.resolve())
        if not src.is_file():
            logger.warning(f"Source file not found: {src}")
            continue
            
        outdir = chunks_dir / src.stem
        outdir.mkdir(exist_ok=True)

        have = sorted([str(f) for f in outdir.glob("seg_*.wav")])

        if not have and ffmpeg_exists():
            # split + trim silence both ends
            try:
                subprocess.run([
                    "ffmpeg", "-hide_banner", "-y", "-i", src_str,
                    "-ac", "1", "-ar", str(TARGET_SR),
                    "-af", "silenceremove=start_periods=1:start_threshold=-45dB:start_silence=0.15,"
                          "areverse,silenceremove=start_periods=1:start_threshold=-45dB:start_silence=0.15,areverse",
                    "-f", "segment", "-segment_time", str(seg_sec), "-reset_timestamps", "1",
                    str(outdir / "seg_%03d.wav")
                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True, timeout=300)
                have = sorted([str(f) for f in outdir.glob("seg_*.wav")])
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
                logger.warning(f"ffmpeg segmentation failed for {src.name}: {e}")
                # fallback: single cleaned wav
                single = outdir / "seg_000.wav"
                try:
                    subprocess.run([
                        "ffmpeg", "-hide_banner", "-y", "-i", src_str,
                        "-ac", "1", "-ar", str(TARGET_SR), "-c:a", "pcm_s16le",
                        str(single)
                    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True, timeout=120)
                    have = [str(single)]
                except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
                    logger.error(f"ffmpeg conversion failed for {src.name}: {e}")

        surfaced.extend(have)

    surfaced = sorted(surfaced)
    return surfaced[:max_copy] if surfaced else []

def list_available_models(model_dir: str) -> List[str]:
    """List all .gguf model files in the model directory."""
    try:
        model_path = Path(model_dir)
        if not model_path.exists():
            return []
        models = sorted([str(f) for f in model_path.glob("*.gguf")])
        return models
    except Exception as e:
        logger.error(f"Error listing models: {e}")
        return []

def discover_voices(base_dir: str) -> dict:
    """
    Discover available voices in the voice base directory.
    Returns dict of {voice_name: path}
    """
    voices = {}
    try:
        base_path = Path(base_dir)
        if not base_path.exists():
            return voices
        
        # Look for direct subdirectories
        for item in base_path.iterdir():
            if item.is_dir():
                voices[item.name] = str(item)
        
        # Also check for chunks subdirectories (like "chunks/The Lich")
        chunks_dir = base_path / "freeman_refs" / "chunks"
        if chunks_dir.exists():
            for item in chunks_dir.iterdir():
                if item.is_dir():
                    voice_name = f"chunks/{item.name}"
                    voices[voice_name] = str(item)
                    
    except Exception as e:
        logger.error(f"Error discovering voices: {e}")
    
    return voices

def select_voice_interactive(base_dir: str) -> str:
    """Interactive voice selection menu."""
    voices = discover_voices(base_dir)
    
    if not voices:
        logger.warning(f"No voices found in {base_dir}")
        return REF_AUDIO_DIR
    
    print("\nüéôÔ∏è  Available voices:")
    voice_list = list(voices.items())
    for i, (name, path) in enumerate(voice_list, 1):
        print(f"  {i}. {name}")
    print(f"  0. Use default ({os.path.basename(REF_AUDIO_DIR)})")
    
    try:
        choice = input("\nüé§ Select voice number (or press Enter for default): ").strip()
        if not choice or choice == "0":
            return REF_AUDIO_DIR
        
        idx = int(choice) - 1
        if 0 <= idx < len(voice_list):
            selected_name, selected_path = voice_list[idx]
            print(f"‚úÖ Selected voice: {selected_name}")
            return selected_path
        else:
            print("‚ö†Ô∏è  Invalid selection, using default")
            return REF_AUDIO_DIR
    except (ValueError, KeyboardInterrupt):
        print("\n‚ö†Ô∏è  Using default voice")
        return REF_AUDIO_DIR

# ------------- LLM streaming helpers -------------
def flushable_phrase(buf: str) -> Tuple[Optional[str], str]:
    """
    Extract a complete phrase from buffer for TTS if ready.
    Prioritizes complete sentences for smoother, more natural speech.
    Returns (phrase, remaining_buffer) or (None, original_buffer).
    """
    if not buf:
        return None, buf
    
    # Only flush on complete sentences (. ? !)
    if len(buf) >= MIN_CHARS_TO_FLUSH:
        last_p = max((buf.rfind(p) for p in PUNCT), default=-1)
        if last_p != -1:
            phrase = buf[:last_p+1].strip()
            rest   = buf[last_p+1:].lstrip()
            if len(phrase) >= 20:  # Increased from 10 - ensure substantial phrases
                return phrase, rest
    
    # Only force break if buffer gets very long
    if len(buf) >= PHRASE_CHAR_MAX:
        last_p = max((buf.rfind(p) for p in PUNCT), default=-1)
        if last_p != -1:
            phrase = buf[:last_p+1].strip()
            rest   = buf[last_p+1:].lstrip()
            if len(phrase) >= 20:
                return phrase, rest
        
        # Last resort: break at word boundary only if extremely long
        cut = buf.rfind(' ', 0, PHRASE_CHAR_MAX)
        if cut == -1:
            cut = PHRASE_CHAR_MAX
        phrase = buf[:cut].strip()
        rest   = buf[cut:].lstrip()
        if len(phrase) >= 20:
            return phrase, rest
    
    return None, buf

# ===================== Global chat memory (RAM only) =====================
CHAT_HISTORY: List[dict] = []

def _trim_chat_history():
    """Trim chat history to prevent unbounded memory growth."""
    global CHAT_HISTORY
    if len(CHAT_HISTORY) > MAX_HISTORY_MESSAGES:
        # Keep only the most recent messages
        removed = len(CHAT_HISTORY) - MAX_HISTORY_MESSAGES
        CHAT_HISTORY = CHAT_HISTORY[-MAX_HISTORY_MESSAGES:]
        logger.debug(f"Trimmed {removed} old messages from history")

def _wipe_history_on_exit():
    """Securely wipe chat history on exit (best-effort)."""
    if not WIPE_HISTORY_ON_EXIT:
        return
    try:
        # Overwrite contents before clearing
        for entry in CHAT_HISTORY:
            for key in list(entry.keys()):
                entry[key] = ""
            entry.clear()
        CHAT_HISTORY.clear()
        logger.debug("Chat history wiped")
    except Exception as e:
        logger.error(f"Failed to wipe history: {e}")

atexit.register(_wipe_history_on_exit)

# Signal handling for graceful shutdown
def _handle_signal(sig, frame):
    """Handle termination signals gracefully."""
    logger.info(f"Received signal {sig}, shutting down...")
    try:
        _wipe_history_on_exit()
        _cleanup_temps()
    finally:
        # Re-raise default behavior
        signal.signal(sig, signal.SIG_DFL)
        os.kill(os.getpid(), sig)

# Register signal handlers (cross-platform)
signals_to_handle = [signal.SIGINT]
if hasattr(signal, 'SIGTERM'):
    signals_to_handle.append(signal.SIGTERM)

for _sig in signals_to_handle:
    try:
        signal.signal(_sig, _handle_signal)
    except (OSError, ValueError) as e:
        logger.warning(f"Could not register signal handler for {_sig}: {e}")

# ===================== TTS worker =====================
def run_tts_worker():
    """Run TTS worker subprocess that receives text via stdin and plays audio."""
    import numpy as np
    import soundfile as sf

    # Safe unpickle for XTTS with newer torch restrictions (best-effort)
    try:
        from torch.serialization import add_safe_globals
        from TTS.tts.configs.xtts_config import XttsConfig
        from TTS.tts.models.xtts import Xtts, XttsAudioConfig, XttsArgs
        from TTS.config.shared_configs import BaseDatasetConfig
        add_safe_globals([XttsConfig, Xtts, XttsArgs, XttsAudioConfig, BaseDatasetConfig])
    except (ImportError, AttributeError):
        pass

    # GPU selection for worker
    tts_force_index = os.environ.get("GPU_TTS_FORCE_INDEX", "").strip()
    if tts_force_index:
        os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
        os.environ["CUDA_VISIBLE_DEVICES"] = tts_force_index

    logger.info("=" * 64)
    logger.info(f"TTS Worker CUDA_VISIBLE_DEVICES = {os.environ.get('CUDA_VISIBLE_DEVICES', '<cpu>')}")
    logger.info("=" * 64)

    # Prepare references (auto-split)
    refs_arg = None
    if "--refs" in sys.argv:
        idx = sys.argv.index("--refs")
        if idx + 1 < len(sys.argv):
            refs_arg = sys.argv[idx + 1]
    refs_dir = refs_arg or REF_AUDIO_DIR
    segs = auto_split_refs(refs_dir, SEG_SEC, MAX_REF_CLIPS)
    
    if not segs:
        logger.warning(f"No reference segments found in: {refs_dir}")
        logger.info("Will use default XTTS voice.")
    else:
        logger.info(f"Using {len(segs)} reference segments")

    # Load TTS
    use_gpu = os.environ.get("CUDA_VISIBLE_DEVICES", "") not in ("", "<cpu>")
    logger.info(f"Loading XTTS (gpu={use_gpu})...")
    
    try:
        from TTS.api import TTS as TTS_API
        tts = TTS_API(model_name=XTTS_MODEL_NAME, gpu=use_gpu)
    except Exception as e:
        logger.error(f"Failed to load TTS model: {e}")
        sys.exit(1)

    def synth_to_file(text: str) -> str:
        """Synthesize text to audio file and return path."""
        wav = tts.tts(
            text=text,
            speaker_wav=segs if segs else None,
            language=TTS_LANGUAGE,
            split_sentences=False,
            speed=SPEECH_SPEED  # Apply speed multiplier
        )
        if isinstance(wav, list):
            wav = np.concatenate([np.atleast_1d(x) for x in wav])
        x = np.asarray(wav, dtype=np.float32)
        # peak limit
        peak = float(np.max(np.abs(x))) if x.size else 0.0
        if peak > 1e-8:
            target = 10.0 ** (PEAK_DBFS / 20.0)
            x *= (target / peak)
        tmp = _get_temp_file(suffix=".wav")
        sf.write(tmp, x, TARGET_SR, subtype="PCM_16")
        return tmp

    # Signal ready to parent process
    print("[TTS] READY", flush=True)
    logger.info("TTS worker ready, awaiting text input...")

    # Process text from stdin
    for line in sys.stdin:
        line = line.strip()
        if not line:
            continue
        try:
            out = synth_to_file(line)
            ok = play_wav_file(out)
            if not ok:
                logger.warning("Could not play audio (no audio device available?)")
        except Exception as e:
            logger.error(f"TTS synthesis error: {e}", exc_info=True)

# ===================== Main (LLM + phrase streaming) =====================
def main():
    """Main chatbot loop with LLM and TTS integration."""
    global REF_AUDIO_DIR

    # Voice selection at startup - ALWAYS prompt before loading anything
    print("\n" + "=" * 64)
    print("VOICE SELECTION")
    print("=" * 64)
    voices = discover_voices(VOICE_BASE_DIR)
    
    if voices:
        print("\nAvailable voices:")
        voice_list = list(voices.items())
        for i, (name, path) in enumerate(voice_list, 1):
            print(f"  {i}. {name}")
        
        while True:
            try:
                choice = input(f"\nSelect voice (1-{len(voice_list)}): ").strip()
                if choice.isdigit():
                    idx = int(choice) - 1
                    if 0 <= idx < len(voice_list):
                        selected_name, selected_path = voice_list[idx]
                        REF_AUDIO_DIR = selected_path
                        print(f"Selected: {selected_name}\n")
                        break
                print(f"Please enter a number between 1 and {len(voice_list)}")
            except KeyboardInterrupt:
                print("\n\nExiting...")
                sys.exit(0)
    else:
        print(f"\nNo voices found in {VOICE_BASE_DIR}")
        print(f"Using default: {REF_AUDIO_DIR}\n")
    
    # Validate model path early
    model_path = MODEL_PATH
    
    # Optional CLI override for model path
    for i, arg in enumerate(sys.argv):
        if i == 0 or arg.startswith("--"):
            continue
        if os.path.exists(arg):
            model_path = arg
            break
    
    if not os.path.isfile(model_path):
        logger.error(f"Model file not found: {model_path}")
        sys.exit(1)

    # DUAL GPU SETUP: Pin LLM to largest VRAM GPU (your 6GB)
    if not IS_TTS_WORKER:
        llm_force_index = os.environ.get("GPU_LLM_FORCE_INDEX")
        if llm_force_index is None:
            llm_force_index = _largest_vram_index()  # Will pick GPU 0 (6GB)
        
        if llm_force_index and llm_force_index != "":
            os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
            os.environ["CUDA_VISIBLE_DEVICES"] = llm_force_index
            logger.info(f"üéÆ LLM assigned to GPU {llm_force_index} (largest VRAM)")

    logger.info("=" * 64)
    logger.info(f"Main Process CUDA_VISIBLE_DEVICES = {os.environ.get('CUDA_VISIBLE_DEVICES', '<cpu>')}")
    logger.info(f"Script: {os.path.abspath(__file__)}")
    logger.info("=" * 64)

    # Load LLM
    logger.info("ü¶ô Loading LLaMA model...")
    from llama_cpp import Llama

    def create_llm(n_gpu_layers: int):
        return Llama(
            model_path=model_path,
            chat_format="chatml",
            n_ctx=N_CTX,
            n_threads=N_THREADS,
            n_batch=N_BATCH,
            n_gpu_layers=n_gpu_layers,
            verbose=False
        )

    try:
        llm = create_llm(N_GPU_LAYERS)
        logger.info("‚úÖ LLM loaded successfully")
    except Exception as e:
        logger.warning(f"GPU load failed ({e}), trying CPU fallback...")
        try:
            llm = create_llm(0)
            logger.info("‚úÖ LLM loaded on CPU")
        except Exception as e2:
            logger.error(f"Failed to load LLM: {e2}")
            sys.exit(1)

    # Launch TTS worker on SECOND GPU (your 3GB)
    tts_env = dict(os.environ)
    tts_index = os.environ.get("GPU_TTS_FORCE_INDEX", "").strip()
    
    # If not manually set, try to use second GPU
    if not tts_index:
        gpus = _gpu_list()
        if len(gpus) >= 2:
            # Sort by VRAM, get second largest (your 3GB)
            sorted_gpus = sorted(gpus, key=lambda x: x[1], reverse=True)
            tts_index = str(sorted_gpus[1][0])  # Second GPU
            logger.info(f"üéÆ TTS assigned to GPU {tts_index} (secondary GPU)")
        else:
            logger.info("‚ö†Ô∏è Only one GPU detected, LLM and TTS will share")
    
    if tts_index:
        tts_env["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
        tts_env["CUDA_VISIBLE_DEVICES"] = tts_index

    cmd = [sys.executable, "-u", os.path.abspath(__file__), "--tts-worker", "--refs", REF_AUDIO_DIR]
    logger.info(f"‚ñ∂Ô∏è  Launching TTS worker: {' '.join(cmd)}")
    
    try:
        proc = subprocess.Popen(
            cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            env=tts_env,
            text=True,
            bufsize=1
        )
    except Exception as e:
        logger.error(f"Failed to launch TTS worker: {e}")
        sys.exit(1)

    # Wait for TTS worker ready signal with timeout
    ready = False
    start_time = time.time()
    
    def pump_worker():
        """Forward worker logs to our stdout."""
        nonlocal ready
        try:
            for ln in proc.stdout:
                print(ln.rstrip())
                if "[TTS] READY" in ln:
                    ready = True
        except Exception:
            pass

    pump_thread = threading.Thread(target=pump_worker, daemon=True)
    pump_thread.start()

    # Wait for ready signal
    while not ready and (time.time() - start_time) < TTS_WORKER_READY_TIMEOUT:
        if proc.poll() is not None:
            logger.error("TTS worker process died during startup")
            sys.exit(1)
        time.sleep(0.1)

    if not ready:
        logger.error(f"TTS worker did not become ready within {TTS_WORKER_READY_TIMEOUT}s")
        proc.terminate()
        sys.exit(1)

    logger.info("‚úÖ TTS worker ready")

    # Voice input setup
    use_voice = VOICE_INPUT_ENABLED and VOICE_INPUT_AVAILABLE
    recognizer = None
    microphone = None
    
    if use_voice:
        if not VOICE_INPUT_AVAILABLE:
            logger.warning("‚ö†Ô∏è  speech_recognition not installed. Install with: pip install SpeechRecognition pyaudio")
            logger.info("Falling back to text input")
            use_voice = False
        else:
            try:
                recognizer = sr.Recognizer()
                microphone = sr.Microphone()
                
                # Adjust for ambient noise
                logger.info("üé§ Calibrating microphone for ambient noise (2 seconds)...")
                with microphone as source:
                    recognizer.energy_threshold = VOICE_ENERGY_THRESHOLD
                    recognizer.pause_threshold = VOICE_PAUSE_THRESHOLD
                    recognizer.adjust_for_ambient_noise(source, duration=2)
                
                logger.info(f"‚úÖ Voice input ready! (energy threshold: {recognizer.energy_threshold})")
            except Exception as e:
                logger.error(f"Failed to initialize microphone: {e}")
                logger.info("Falling back to text input")
                use_voice = False

    # Chat loop
    character_prompt = DEFAULT_CHARACTER
    tts_worker_alive = True

    print(f"\nü§ñ Character set to:\n  ¬ª {character_prompt}")
    print(f"üíæ Max history: {MAX_HISTORY_MESSAGES} messages")
    print(f"üì¶ Current model: {os.path.basename(model_path)}")
    print(f"üéôÔ∏è  Current voice: {os.path.basename(REF_AUDIO_DIR)}")
    if use_voice:
        print("üé§ Voice input ENABLED - speak into your mic!")
        print("   (Say 'exit' or 'quit' to end, or press Ctrl+C)")
    print("Commands: /character <prompt> | /show_character | /models | /voices | /text (switch to text) | exit/quit\n")

    try:
        while True:
            # Get user input (voice or text)
            if use_voice:
                try:
                    print("üé§ Listening... (speak now)", end="", flush=True)
                    with microphone as source:
                        audio = recognizer.listen(source, timeout=None, phrase_time_limit=10)
                    
                    print("\rüé§ Processing speech...    ", end="", flush=True)
                    try:
                        # Use Google's free speech recognition
                        user = recognizer.recognize_google(audio)
                        print(f"\rüó£Ô∏è  You: {user}                    ")
                    except sr.UnknownValueError:
                        print("\r‚ö†Ô∏è  Couldn't understand that. Try again.    ")
                        continue
                    except sr.RequestError as e:
                        print(f"\r‚ö†Ô∏è  Speech recognition error: {e}    ")
                        continue
                        
                except KeyboardInterrupt:
                    raise
                except Exception as e:
                    logger.error(f"Voice input error: {e}")
                    print("\nFalling back to text input for this message.")
                    user = input("üó£Ô∏è  You: ").strip()
            else:
                try:
                    user = input("üó£Ô∏è  You: ").strip()
                except EOFError:
                    break

            if user.lower() in ("exit", "quit"):
                break

            # Handle commands
            if user.startswith("/character "):
                character_prompt = user[len("/character "):].strip()
                print(f"‚úÖ Character updated:\n  ¬ª {character_prompt}")
                continue
            
            if user == "/show_character":
                print(f"üìù Current character:\n  ¬ª {character_prompt}")
                continue
            
            if user == "/models":
                available = list_available_models(MODEL_DIR)
                if not available:
                    print(f"‚ö†Ô∏è  No models found in {MODEL_DIR}")
                else:
                    print(f"\nüì¶ Available models in {MODEL_DIR}:")
                    for i, m in enumerate(available, 1):
                        current = "‚úì" if m == model_path else " "
                        print(f"  [{current}] {i}. {os.path.basename(m)}")
                    print(f"\nüí° To switch models, restart with a different model:")
                    print(f"   python {os.path.basename(__file__)} /path/to/model.gguf")
                    print(f"   Or edit MODEL_PATH in the script\n")
                continue
            
            if user == "/voices":
                voices = discover_voices(VOICE_BASE_DIR)
                if not voices:
                    print(f"‚ö†Ô∏è  No voices found in {VOICE_BASE_DIR}")
                else:
                    current_voice = os.path.basename(REF_AUDIO_DIR)
                    print(f"\nüéôÔ∏è  Available voices:")
                    for name, path in sorted(voices.items()):
                        marker = "‚úì" if path == REF_AUDIO_DIR else " "
                        print(f"  [{marker}] {name}")
                    print(f"\nüí° To switch voices, restart with --select-voice:")
                    print(f"   python {os.path.basename(__file__)} --select-voice")
                    print(f"   Or use --refs flag:")
                    print(f"   python {os.path.basename(__file__)} --refs /path/to/voice\n")
                continue
            
            if user == "/text":
                use_voice = False
                print("‚úÖ Switched to text input")
                continue
                
            if user == "/voice" and VOICE_INPUT_AVAILABLE:
                if recognizer and microphone:
                    use_voice = True
                    print("‚úÖ Switched to voice input")
                else:
                    print("‚ö†Ô∏è  Voice input not available")
                continue
            
            if user.startswith("/voice refs "):
                newdir = user[len("/voice refs "):].strip()
                if os.path.isdir(newdir):
                    REF_AUDIO_DIR = newdir
                    print(f"üîÅ Restart required to use new refs dir: {REF_AUDIO_DIR}")
                else:
                    print(f"‚ö†Ô∏è  Not a directory: {newdir}")
                continue

            if not user:
                continue

            # Build messages with current in-RAM history
            system = f"{character_prompt} Answer in 1‚Äì3 short sentences max."
            CHAT_HISTORY.append({"role": "user", "content": user})
            _trim_chat_history()
            
            messages = [{"role": "system", "content": system}] + CHAT_HISTORY

            print("ü§ñ Thinking & speaking...")
            full_raw: List[str] = []
            buf = ""
            print("\nüß† Assistant:", end=" ", flush=True)

            try:
                stream = llm.create_chat_completion(
                    messages=messages,
                    temperature=0.7, top_p=0.9,
                    max_tokens=MAX_TOKENS,
                    stop=["User:", "USER:", "###"],
                    stream=True
                )

                for ev in stream:
                    delta = ev["choices"][0]["delta"].get("content", "")
                    if not delta:
                        continue
                    full_raw.append(delta)
                    buf += delta

                    phrase, buf = flushable_phrase(buf)
                    if phrase:
                        print(phrase, end=" ", flush=True)
                        # send to TTS
                        if tts_worker_alive:
                            try:
                                if proc.poll() is None and proc.stdin:
                                    proc.stdin.write(phrase + "\n")
                                    proc.stdin.flush()
                                else:
                                    logger.warning("TTS worker died, continuing without audio")
                                    tts_worker_alive = False
                            except (BrokenPipeError, OSError) as e:
                                logger.warning(f"TTS pipe error: {e}")
                                tts_worker_alive = False

                # leftover
                leftover = buf.strip()
                if leftover:
                    print(leftover, end=" ", flush=True)
                    if tts_worker_alive:
                        try:
                            if proc.poll() is None and proc.stdin:
                                proc.stdin.write(leftover + "\n")
                                proc.stdin.flush()
                            else:
                                tts_worker_alive = False
                        except (BrokenPipeError, OSError):
                            tts_worker_alive = False

                print()  # newline

                # Save compact cleaned text to in-RAM history
                final_text = re.sub(r"\s+", " ", "".join(full_raw)).strip()
                CHAT_HISTORY.append({"role": "assistant", "content": final_text})

            except Exception as e:
                logger.error(f"LLM generation error: {e}", exc_info=True)
                print("\n‚ö†Ô∏è  An error occurred during generation.")

    except KeyboardInterrupt:
        print("\nüëã Interrupted.")
    finally:
        # Stop TTS worker gracefully
        logger.info("Shutting down TTS worker...")
        try:
            if proc and proc.poll() is None:
                if proc.stdin:
                    try:
                        proc.stdin.close()
                    except Exception:
                        pass
                proc.terminate()
                try:
                    proc.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    logger.warning("TTS worker didn't terminate, killing...")
                    proc.kill()
        except Exception as e:
            logger.error(f"Error stopping TTS worker: {e}")

# ================= Entrypoint =================
if __name__ == "__main__":
    if IS_TTS_WORKER:
        run_tts_worker()
    else:
        main()
